import os
from dotenv import load_dotenv
from langchain_text_splitters import RecursiveCharacterTextSplitter
from loguru import logger
import json
# from tqdm import tqdm
from threading import Lock
from collections import Counter
import pandas as pd
# import re
import sys
import re

import numpy as np
import faiss
# import getpass
from langchain_community.vectorstores import FAISS
from langgraph.graph import StateGraph
import requests
# import os.path
# import langchain_text_splitters.html
from langchain_core.documents import Document
from sentence_transformers import CrossEncoder
# import operator
from typing_extensions import TypedDict
from typing import List, Annotated
from langgraph.graph import END
from openai import OpenAI

#from syte_lera import age_group

LOG_PATH = "rag_logs.log"
logger.remove()
logger.add(sys.stderr, level="DEBUG", backtrace=False, diagnose=False)
# —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏ –¥—è–ª —Ä–∞–∑—Ä–∞–±–æ–≤
logger.add(
    LOG_PATH,
    rotation="10 MB",
    retention="30 days",
    encoding="utf-8",
    level="DEBUG",
    enqueue=True,
    backtrace=True,
    diagnose=True
)

# –õ–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
# logger.add(
#     sys.stdout,
#     level="DEBUG",    # –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å DEBUG –∏ –≤—ã—à–µ
# )
# –ü–†–û–ú–ü–¢–´:
# -------------------------------------------
router_instructions = """
    –¢—ã —è–≤–ª—è–µ–µ—à—å—Å—è —É–º–Ω–µ–π—à–∏–º —ç–∫–æ–Ω–æ–º–∏—Å—Ç–æ–º, –ø–æ–º–æ–≥–∞—é—â–∏–º –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤, –æ—Ç–Ω–æ—Å—è—à–∏—Ö—Å—è –∫ —ç–∫–æ–Ω–æ–º–∏–∫–µ –∏–ª–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏.
    –¢—ã –º–æ–∂–µ—à—å –Ω–∞–ø—Ä–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ vectorstore –∏–ª–∏ –≤ autoanswer, –∞ —Ç–∞–∫–∂–µ —Ç–≤–æ—è –∑–∞–¥–∞—á–∞ - –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–ª—è –Ω–∏—Ö
    —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç—ç–≥–∏ –∏–∑ —Å—Ç—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è '–°–ü–ò–°–û–ö –î–û–°–¢–£–ü–ù–´–• –¢–≠–ì–û–í', –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–µ–±–µ –Ω–∏–∂–µ –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç 17 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç—ç–≥–æ–≤, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑
    –∑–∞–ø—è—Ç—É—é.

    –°–ü–ò–°–û–ö –î–û–°–¢–£–ü–ù–´–• –¢–≠–ì–û–í: '–≠–∫–æ–Ω–æ–º–∏–∫–∞', '–ü–æ–¥—Ä–∞–±–æ—Ç–∫–∞', '–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã', '–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –≤–∫–ª–∞–¥—ã –∏ –∫—Ä–µ–¥–∏—Ç—ã', '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–ü–æ–∫—É–ø–∫–∏', '–ñ–∏–ª—å–µ',
    '–£—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã', '–ö–∞—Ä–º–∞–Ω–Ω—ã–µ –¥–µ–Ω—å–≥–∏', '–ú–æ—à–µ–Ω–Ω–∏–∫–∏', '–≠–∫–æ–Ω–æ–º–∏—è', '–°–±–µ—Ä–µ–∂–µ–Ω–∏—è', '–ù–∞–ª–æ–≥–∏', '–ü—Ä–∞–≤–∞', '–î–æ–∫—É–º–µ–Ω—Ç—ã', '–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ü–µ–ª–∏', '–ò–Ω–æ–µ'

    –í vectorstore —Å–æ–±—Ä–∞–Ω—ã —Å—Ç–∞—Ç—å–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–±–ª–æ–≥–æ–≤ –¥–ª—è –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤. –í –Ω–∏—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è —Ä–∞–∑–ª–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è - –æ–± —ç–∫–æ–Ω–æ–º–∏–∫–µ, —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏,
    –∑–∞—â–∏—Ç–µ –æ—Ç –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞, –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è—Ö, —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–∏, –ø–µ–Ω—Å–∏—è—Ö –∏ –º–Ω–æ–≥–æ–º –¥—Ä—É–≥–æ–º. 

    –î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Å—Ö–æ–∂–∏–º —Ç–µ–º–∞–º –Ω–∞–¥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å vectorstore.

    –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Å–µ–±–µ –Ω–µ–ø—Ä–∏—Å—Ç–æ–π–Ω—É—é –ª–µ–∫—Å–∏–∫—É, –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è, –Ω–µ–∫–∫–æ—Ä–µ–∫—Ç–Ω—ã–µ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –º–æ—Ä–∞–ª–∏ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è,
    –æ—Å—Ç—Ä–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, —Ç–æ –µ—Å—Ç—å –≤—Å–µ, –Ω–∞ —á—Ç–æ –Ω–µ –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –ø–æ–¥—Ä–æ—Å—Ç–∫–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –º–æ—Ä–∞–ª—å–Ω—ã–º —É—Å—Ç–æ—è–º - —Ç–æ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å autoanswer.
    –ï—Å–ª–∏ –ø–æ–¥—Ä–æ—Å—Ç–æ–∫ –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ –∫—Ç–æ-—Ç–æ –ø—Ä–æ—Å–∏—Ç –æ—Ç –Ω–µ–≥–æ –¥–µ–Ω–µ–≥ - —Ç–æ –Ω—É–∂–Ω–æ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–æ–π—Ç–∏ –≤ vectorstore. 
    –ï—Å–ª–∏ –ø–æ–¥—Ä–æ—Å—Ç–æ–∫ –≥–æ–≤–æ—Ä–∏—Ç –ø—Ä–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è - –æ –Ω—É–∂–Ω–æ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–æ–π—Ç–∏ –≤ vectorstore. 
    –ï—Å–ª–∏ –ø–æ–¥—Ä–æ—Å—Ç–æ–∫ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —ç—Ç–æ –∏–∑ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–≤–æ–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–Ω –¥–µ–ª–∏—Ç—Å—è —Å–∏—Ç—É–∞—Ü–∏–µ–π –∏–∑ –∂–∏–∑–Ω–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π –æ–Ω –º–æ–≥ —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å –º–æ—à–µ–Ω–Ω–∏–∫–æ–º, —Ç–æ –Ω—É–∂–Ω–æ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–æ–π—Ç–∏ –≤ vectorstore.
    –¢–∞–∫ –Ω–∏–∫—Ç–æ –Ω–µ –ø–æ—Ç–µ—Ä—è–µ—Ç —Ä–µ–ø—É—Ç–∞—Ü–∏—é, –∞ –ø–æ–¥—Ä–æ—Å—Ç–æ–∫ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –¥–æ–≤–æ–ª–µ–Ω –æ—Ç–≤–µ—Ç–æ–º.

    –ï—Å–ª–∏ —Ç—ã —Ä–µ—à–∏–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å vectorstore –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞, —Ç–æ –∫ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É —Ç–µ–±–µ —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç—ç–≥–∏ –ø–æ —Å–ª–µ–¥—É—é—â–µ–π –∏–Ω—Ç—Å—Ä—É–∫—Ü–∏–∏:
    1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ 3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç—ç–≥–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ
    2. –¢—ç–≥–∏ –¥–æ–ª–∂–Ω—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—Ç—å —Å—É—Ç—å –≤–æ–ø—Ä–æ—Å–∞ –∏ –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ (—Ç–æ –µ—Å—Ç—å —Å—Ä–µ–¥–∏ —Ç—Ä–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç—ç–≥–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–≤—É—Ö –∏–ª–∏ —Ç—Ä–µ—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö)
    3. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–º, –ø–æ–¥–±–µ—Ä–∏ —Ç—Ä–∏ —Ç—ç–≥–∞ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω–æ –æ—Ö–≤–∞—Ç—ã–≤–∞–ª–∏ –≤—Å–µ —Ç–µ–º—ã –≤–æ–ø—Ä–æ—Å–∞
    4. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π —Ä–æ–≤–Ω–æ 3 —Ç—ç–≥–∞
    5. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –¢–≠–ì–ò –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –°–ü–ò–°–ö–ê –î–û–°–¢–£–ü–ù–´–• –¢–≠–ì–û–í

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê - –¢–û–õ–¨–ö–û JSON:
{
    "datasource": "vectorstore",
    "tags": ["—Ç—ç–≥1", "—Ç—ç–≥2", "—Ç—ç–≥3"]
}

–ò–õ–ò:
{
    "datasource": "autoanswer",
    "tags": []
}
"""

rag_prompt = """ –¢—ã - —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —á–∞—Ç-–±–æ—Ç –¥–ª—è –ø–æ–¥—Ä–æ—Å—Ç–∫–æ–≤, –ø–æ–º–æ–≥–∞—é—â–∏–π –º–æ–ª–æ–¥–µ–∂–∏ –ø–æ–∑–Ω–∞–≤–∞—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å. –¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø . –¢—ã –º–æ–∂–µ—à—å –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
    –ü–æ–º–Ω–∏ - –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ü–û–î–†–û–°–¢–ö–ê. –ù–µ –ø–∏—à–∏ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ –∏ –Ω—É–¥–Ω–æ, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–π –≤—Å–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏ –≥–ª–∞–≤–Ω–æ–µ - –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ. –ò–Ω–æ–≥–¥–∞ –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏.
    –ò–ª–∏ –∏–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä—ã—Ö —Å–ª–æ–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –ø–æ–Ω—è—Ç—å. 
    –í–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: 
    {age_group}
    
    –≠—Ç–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å:
    {context} 
    
    –¢—â–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—É–º–∞–π –Ω–∞–¥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. –û–¥–Ω–∞–∫–æ, —Ç–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –≤ –æ—Ç–≤–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ç–æ, —á—Ç–æ —Ç—ã –æ–ø–∏—Ä–∞–µ—à—å—Å—è –Ω–∞ –∫–∞–∫–æ–π-—Ç–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    
    –¢–µ–ø–µ—Ä—å –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
    
    {question}
    
    –ò—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∑–∞–¥–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å. –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–±—à–∏—Ä–Ω—ã–º, –∏ –¥–∞–≤–∞—Ç—å –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ,
    –∫–æ—Ç–æ—Ä–æ–π –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å. –û—Ç–≤–µ—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ª–æ–∂–Ω–æ–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç —É–ø—Ä–æ—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ - —É–ø—Ä–æ—Å—Ç–∏, –Ω–æ –æ—Ç–≤–µ—Ç—å –ø–æ–ª–Ω–æ. –ò–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π –∏ —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ –≤ —Å–ª—É—á–∞–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏), —Ç–æ —Å–¥–µ–ª–∞–π —ç—Ç–æ.
    –°—Ç–∞—Ä–∞–π—Å—è –¥–∞—Ç—å –æ—Ç–≤–µ—Ç –≤ —Ç–æ–π —Ñ–æ—Ä–º–µ, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–æ—Ç–≤–µ—Å—Ç–≤–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç—É —Ç–≤–æ–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ï—Å–ª–∏ –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 10-14 –Ω–µ –ø–∏—à–∏ –º–Ω–æ–≥–æ –ø—Ä–æ –ø–æ–¥—Ä–∞–±–æ—Ç–∫—É/—Ä–∞–±–æ—Ç—É/–∑–∞—Ä–ø–ª–∞—Ç—É –∏ –¥—Ä—É–≥–∏–µ —Å–ª–æ–∂–Ω—ã–µ –¥–ª—è —Ä–µ–±–Ω–∫–∞ –≤–µ—â–∏, —Å—Ç–∞—Ä–∞–π—Å—è –æ–±—å—è—Å–Ω—è—Ç—å –≤—Å–µ –Ω–∞ –ø–æ–Ω—è—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö. 
    –ï—Å–ª–∏ –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 14-18 - –º–æ–∂–µ—à—å –ø–∏—Å–∞—Ç—å –ø—Ä–æ –ø–æ–¥—Ä–∞–±–æ—Ç–∫—É/—Ä–∞–±–æ—Ç—É –∏ –ø—Ä–æ—á–∏–µ –≤–∑—Ä–æ—Å–ª—ã–µ –≤–µ—â–∏, —Å—Ç–∞—Ä–∞–π—Å—è –Ω–µ –¥–∞–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.
    
    –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–æ—è—Ç—å –≤ —Å—Ä–µ–¥–Ω–µ–º –∏–∑ –±–æ–ª–µ–µ —á–µ–º 6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ï—Å–ª–∏ —Ç—ã –¥—É–º–∞—à–µ—å, —á—Ç–æ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø–æ—è—Å–Ω–µ–Ω–∏–π - –∏—Å–ø–æ–ª—å–∑—É–π –±–æ–ª—å—à–µ —Å–ª–æ–≤. –ù–µ –ø–∏—à–∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    –ï—â–µ —Ä–∞–∑: —Ç–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –¢–û–ß–ù–û –∏ –®–ò–†–û–ö–û –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å.
    
    –ú–æ–∂–µ—à—å –Ω–∞—á–∞—Ç—å —Å–≤–æ–π –æ—Ç–≤–µ—Ç —Å: "–ü—Ä–∏–≤–µ—Ç! –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è". –ò–ª–∏ –∫–∞–∫-—Ç–æ –ø–æ-–¥—Ä—É–≥–æ–º—É, –Ω–∞ —Ç–≤–æ–π –≤–∫—É—Å –∏ —Ü–≤–µ—Ç. 
    –ï—Å–ª–∏  –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 10-14, —Ç–æ  –¥–æ–±–∞–≤—å "–ü–æ–∫–∞ –¥—Ä—É–∂–æ–∫, –±—É–¥—å –æ—Å—Ç–æ—Ä–æ–∂–µ–Ω –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ!" –≤ –∫–æ–Ω—Ü–µ —Å–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞. –ï—Å–ª–∏ –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 14-18,  –¥–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ —Å–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ "–ü–æ–∫–∞ –ø—Ä–∏—è—Ç–µ–ª—å, –Ω–µ —Ç–µ—Ä—è–π —Å–≤–æ–µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞ –∫ —Ñ–∏–Ω–∞–Ω—Å–∞–º!"

    –û—Ç–≤–µ—Ç:"""

tags_for_docs_instructions = """
    –¢—ã —è–≤–ª—è–µ–µ—à—å—Å—è —É–º–Ω–µ–π—à–∏–º —ç–∫–æ–Ω–æ–º–∏—Å—Ç–æ–º, –ø–æ–º–æ–≥–∞—é—â–∏–º –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã, –æ—Ç–Ω–æ—Å—è—à–∏–µ—Å—è –∫ —ç–∫–æ–Ω–æ–º–∏–∫–µ –∏–ª–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏, –ø–æ –±–æ–ª–µ–µ —É–∑–∫–∏–º —Ç—ç–≥–∞–º.
    –¢–≤–æ—è –∑–∞–¥–∞—á–∞ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–¥–æ–±—Ä–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–∏–µ –µ–º—É 3 —Ç—ç–≥–∞ –∏–∑ "–°–ü–ò–°–û–ö –î–û–°–¢–£–ü–ù–´–• –¢–≠–ì–û–í", —Ç—ç–≥–∏ –¥–æ–ª–∂–Ω—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω–æ –∏ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é —Å—É—Ç—å –∏ —Ç–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç–∞

    –°–ü–ò–°–û–ö –î–û–°–¢–£–ü–ù–´–• –¢–≠–ì–û–í: '–≠–∫–æ–Ω–æ–º–∏–∫–∞', '–ü–æ–¥—Ä–∞–±–æ—Ç–∫–∞', '–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç—ã', '–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –≤–∫–ª–∞–¥—ã –∏ –∫—Ä–µ–¥–∏—Ç—ã', '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–ü–æ–∫—É–ø–∫–∏', '–ñ–∏–ª—å–µ',
    '–£—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã', '–ö–∞—Ä–º–∞–Ω–Ω—ã–µ –¥–µ–Ω—å–≥–∏', '–ú–æ—à–µ–Ω–Ω–∏–∫–∏', '–≠–∫–æ–Ω–æ–º–∏—è', '–°–±–µ—Ä–µ–∂–µ–Ω–∏—è', '–ù–∞–ª–æ–≥–∏', '–ü—Ä–∞–≤–∞', '–î–æ–∫—É–º–µ–Ω—Ç—ã', '–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ü–µ–ª–∏', '–ò–Ω–æ–µ'



    –¢—ç–≥–∏ –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–µ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
    1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç  –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ 3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç—ç–≥–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ
    2. –¢—ç–≥–∏ –¥–æ–ª–∂–Ω—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—Ç—å —Å—É—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ (—Ç–æ –µ—Å—Ç—å —Å—Ä–µ–¥–∏ —Ç—Ä–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç—ç–≥–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–≤—É—Ö –∏–ª–∏ —Ç—Ä–µ—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö)
    3. –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∫–∞—Å–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–º, –ø–æ–¥–±–µ—Ä–∏ —Ç—Ä–∏ —Ç—ç–≥–∞ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω–æ –æ—Ö–≤–∞—Ç—ã–≤–∞–ª–∏ –≤—Å–µ —Ç–µ–º—ã –≤–æ–ø—Ä–æ—Å–∞
    4. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π —Ä–æ–≤–Ω–æ 3 —Ç—ç–≥–∞
    5. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –¢–≠–ì–ò –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –°–ü–ò–°–ö–ê –î–û–°–¢–£–ü–ù–´–• –¢–≠–ì–û–í

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê - –¢–û–õ–¨–ö–û JSON:
{
    "tags": ["—Ç—ç–≥1", "—Ç—ç–≥2", "—Ç—ç–≥3"]
}"""



hallucination_grader_prompt = """–§–ê–ö–¢–´: \n\n {documents} \n\n –û–¢–í–ï–¢ –°–¢–£–î–ï–ù–¢–ê: {generation}. 
–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–Ω–µ —Ç–µ–∫—Å—Ç–æ–º, –∞ –∏–º–µ–Ω–Ω–æ json-—Ñ–∞–π–ª–æ–º) —Å –ø–æ–º–æ—â—å—é –¥–≤—É—Ö –∫–ª—é—á–µ–π, –ø–µ—Ä–≤—ã–π —ç—Ç–æ  binary_score - —ç—Ç–æ –æ—Ü–µ–Ω–∫–∞ "yes" –∏–ª–∏ "no", —á—Ç–æ–±—ã —É–∫–∞–∑–∞—Ç—å, –æ—Å–Ω–æ–≤–∞–Ω –ª–∏ –û–¢–í–ï–¢ –°–¢–£–î–ï–ù–¢–ê –Ω–∞ –§–ê–ö–¢–ê–•. 
–í—Ç–æ—Ä–æ–π –∫–ª—é—á —ç—Ç–æ explanation - –ø–æ—è—Å–Ω–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ  binary_score.
"""

hallucination_grader_instructions = """

–¢—ã —è–≤–ª—è–µ—à—å—Å—è –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–º, –æ—Ü–µ–Ω–∏–≤–∞—é—â–∏–º –æ—Ç–≤–µ—Ç —É—á–∞—â–µ–≥–æ—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞.
–ù–∞ –≤—Ö–æ–¥ —Ç—ã –ø–æ–ª—É—á–∏—à—å –¥–≤–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞:
- –§–ê–ö–¢–´: –∫–ª—é—á–µ–≤–∞—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –∏–∑–≤–ª–µ—á–µ–Ω–Ω–∞—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
- –û–¢–í–ï–¢ –°–¢–£–î–ï–ù–¢–ê: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–¢–≤–æ—è —Ü–µ–ª—å - –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –ª–∏ –û–¢–í–ï–¢ –°–¢–£–î–ï–ù–¢–ê –§–ê–ö–¢–ê–ú–ò. –¢–æ –µ—Å—Ç—å, –æ—Ç—Ä–∞–∂–∞–µ—Ç –ª–∏ –û–¢–í–ï–¢ –°–¢–£–î–ï–ù–¢–ê –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –§–ê–ö–¢–û–í. –ò –±—ã–ª–∞ –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–≥–∏–∫–∞.

–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏:

1. –û—Ç–≤–µ—Ç –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –§–ê–ö–¢–´, –Ω–æ –æ–Ω –¥–æ–ª–∂–µ–Ω –æ—Ç—Ä–∞–∂–∞—Ç—å —Ç–æ –∂–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ –Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç—å –∏–º.
2. –î–æ–ø—É—Å—Ç–∏–º–æ, —á—Ç–æ–±—ã –û–¢–í–ï–¢ –°–¢–£–î–ï–ù–¢–ê –≤–∫–ª—é—á–∞–ª –ª–µ–≥–∫–æ–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ–±–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ —Ä–∞–∑—É–º–Ω—ã–µ –≤—ã–≤–æ–¥—ã, –µ—Å–ª–∏ –æ–Ω–∏
–æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏.
3. –ù–µ –ø–æ–º–µ—á–∞–π –æ—Ç–≤–µ—Ç –∫–∞–∫ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–Ω —è–≤–Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—ã–¥—É–º–∞–Ω–Ω–æ–π, –Ω–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–π –∏–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
 
"""

answer_grader_prompt = """–í–û–ü–†–û–°: \n\n {question} \n\n –û–¢–í–ï–¢ –£–ß–ï–ù–ò–ö–ê: {generation}. 

–í–µ—Ä–Ω–∏ JSON —Å –¥–≤—É–º—è –∫–ª—é—á–∞–º–∏: binary_score —ç—Ç–æ 'yes' –∏–ª–∏ 'no'  - —Å–∫–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –û–¢–í–ï–¢ –£–ß–ï–ù–ò–ö–ê –ø–æ–¥ –∫—Ä–∏—Ç–µ—Ä–∏–∏. 
–ò explanation, –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ—è—Å–Ω—è–µ—Ç –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π binary_score."""

answer_grader_instructions = """
    
    –¢—ã - –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, –æ—Ü–µ–Ω–∏–≤–∞—é—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞. –¢–µ–±–µ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω –í–û–ü–†–û–°, –∑–∞–¥–∞–Ω–Ω—ã–π –£–ß–ï–ù–ò–ö–£, –∏ –û–¢–í–ï–¢ –£–ß–ï–ù–ò–ö–ê. 
    –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–º —Ç–µ–±–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–ª–µ–¥–æ–≤–∞—Ç—å:

    (1) –û–¢–í–ï–¢ –£–ß–ï–ù–ò–ö–ê –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –í–û–ü–†–û–°. 
    (2) –£–ß–ï–ù–ò–ö –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –æ—Å—Ç—Ä–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π, –∞–º–æ—Ä–∞–ª—å–Ω—ã–π –í–û–ü–†–û–°. –£–ß–ï–ù–ò–ö–£ –∫–∞—Ç–µ–≥–æ—Ä–∏—á–µ—Å–∫–∏ –Ω–µ–ª—å–∑—è –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –í–û–ü–†–û–°–´, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç—Å—è
    —Ä–∞—Å–æ–≤–∞—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å —Å –∞–º–æ—Ä–∞–ª—å–Ω–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è, —á–µ—Ä–Ω—ã–π —é–º–æ—Ä, –Ω–µ–ø—Ä–∏—Å—Ç–æ–π–Ω—ã–µ —Ç–µ–º—ã.  
    
    –ü—Ä–∞–≤–∏–ª–∞ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ –£–ß–ï–ù–ò–ö–£:

    –û—Ü–µ–Ω–∫–∞ "yes" –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ—Ç–≤–µ—Ç —É—á–∞—â–µ–≥–æ—Å—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º. –≠—Ç–æ –Ω–∞–∏–≤—ã—Å—à–∏–π –±–∞–ª–ª. 

    –£—á–∞—â–∏–π—Å—è –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É "yes", –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —è–≤–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –≤ –≤–æ–ø—Ä–æ—Å–µ. –ù–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –¥–æ–ª–∂–Ω–∞
    –ø–µ—Ä–µ—á–∏—Ç—å –æ–±—â–∏–º –∂–∏–∑–Ω–µ–Ω–Ω—ã–º –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—è–º. 

    –û—Ü–µ–Ω–∫–∞ "no" –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ—Ç–≤–µ—Ç —É—á–∞—â–µ–≥–æ—Å—è –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º. –≠—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π –±–∞–ª–ª, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –º–æ–∂–µ—à—å –≤—ã—Å—Ç–∞–≤–∏—Ç—å.

    –û–±—ä—è—Å–Ω–∏ —Å–≤–æ–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–æ—ç—Ç–∞–ø–Ω–æ, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Å–≤–æ–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –≤—ã–≤–æ–¥–æ–≤. 

    –ò–∑–±–µ–≥–∞–π –ø—Ä–æ—Å—Ç–æ–≥–æ —É–∫–∞–∑–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –Ω–∞—á–∞–ª–µ.
    
    """

# -------------------------------------------
# –ü–ê–ô–ü–õ–ê–ô–ù:

load_dotenv()


OPENROUTER_API_KEY='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'
# EMBEDDER_API_KEY='sk-UCKjC2dshq8VKM2YVdNxkw'
# #
# LLM_API_KEY = os.getenv("LLM_API_KEY")
# # –ü–æ–¥–∫–ª—é—á–∞–µ–º –∫–ª—é—á –¥–ª—è EMBEDDER-–º–æ–¥–µ–ª–∏
# EMBEDDER_API_KEY = os.getenv("EMBEDDER_API_KEY")
cross_encoder = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")


llm_client = OpenAI(
        # –ë–∞–∑–æ–≤—ã–π url - —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        base_url="https://openrouter.ai/api/v1/",
        # –£–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—à –∫–ª—é—á, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä–∞–Ω–µ–µ
        api_key=OPENROUTER_API_KEY,
    )

embed_client = OpenAI(
    base_url="https://openrouter.ai/api/v1/",
    api_key=OPENROUTER_API_KEY,
)


# —à—Ç—É–∫–∞ –¥–ª—è —Ç–µ–≥–æ–≤
TAG_HISTORY = []
TAG_HISTORY_LOCK = Lock()

def add_tags_to_session(tags):
    if not tags:
        return
    if isinstance(tags, str):
        tags = [tags]
    with TAG_HISTORY_LOCK:
        for t in tags:
            if isinstance(t, str) and t.strip():
                TAG_HISTORY.append(t.strip())

def reset_tag_history():
    with TAG_HISTORY_LOCK:
        TAG_HISTORY.clear()

def get_tag_stats():
    with TAG_HISTORY_LOCK:
        return dict(Counter(TAG_HISTORY))

# ------------------------


def llm_generate(prompt_text: str):

    response = llm_client.chat.completions.create(
        model="google/gemini-2.0-flash-001",
        temperature=0.1,
        messages=[
            {
                "role": "user",
                "content": [{"type": "text", "text": prompt_text}]
            }
        ]
    )
    return response.choices[0].message.content


def llm_json(prompt_text: str, system_text: str = ""):

    messages = []
    if system_text:
        messages.append({
            "role": "system",
            "content": [{"type": "text", "text": system_text}]
        })
    messages.append({
        "role": "user",
        "content": [{"type": "text", "text": prompt_text}]
    })

    response = llm_client.chat.completions.create(
        model="google/gemini-2.0-flash-001",
        messages=messages,
        temperature=0.1
    )
    return response.choices[0].message.content



def rerank_docs_local(query, docs):

    pairs = [(query, doc) for doc in docs]
    scores = cross_encoder.predict(pairs)
    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)

    return ranked_indices, scores


def get_embedding(text):
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1/",
        api_key=OPENROUTER_API_KEY,
    )
    response = client.embeddings.create(
        model="openai/text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding


def extract_json(text):
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(0))
        except json.JSONDecodeError as e:
            print("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON:", e)
            return None
    else:
        print("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ")
        return None

def autoanswer(state):

    logger.debug("---–ê–í–¢–û–û–¢–í–ï–¢ –ù–ê –ù–ï–ö–û–†–†–ï–ö–¢–ù–´–ô –í–û–ü–†–û–°---")
    return {"generation": "–ö–∞–∂–µ—Ç—Å—è,—è –µ—â–µ –Ω–µ –Ω–∞—É—á–∏–ª—Å—è –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ø–æ–¥–æ–±–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã!:("}



def load_train_csv(file_path: str = "./train_data_child.csv"):

    dff = pd.read_csv(file_path)

    documents = []
    for _, row in dff.iterrows():

        combined_text = f"{row.iloc[1]} {row.iloc[2]}"

        tags_for_doc = llm_json(
            prompt_text=combined_text,
            system_text=tags_for_docs_instructions
        )
        tags_for_doc = tags_for_doc.replace("```json", "").replace("```", "").strip()
        doc_tags = json.loads(tags_for_doc)["tags"]
        doc_tags=[tag.strip().strip("'\"") for tag in doc_tags]
        metadata = {
            "source": file_path,

            "tags": doc_tags
        }

        documents.append(Document(page_content=combined_text, metadata=metadata))

    return documents

def split_documents(documents: list, chunk_size: int =7500, chunk_overlap: int = 1500) -> list:

    logger.debug(f"–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏: chunk_size={chunk_size}, chunk_overlap={chunk_overlap}")
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separators=['!','?','.'])
    return splitter.split_documents(documents)


class EmbeddingWrapper:
    def embed_documents(self, texts):
        return [get_embedding(t) for t in texts]

    def embed_query(self, query):
        return get_embedding(query)


    def __call__(self, text):
        return self.embed_query(text)

# embedding_wrapper = EmbeddingWrapper()

def indexed_df():
    embedding_wrapper = EmbeddingWrapper()
    index_path = "faiss_index"

    if os.path.isdir(index_path):
        try:
            logger.debug(f" –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ FAISS –∏–∑ {index_path}")
            db = FAISS.load_local(
                index_path,
                embeddings=embedding_wrapper,
                allow_dangerous_deserialization=True
            )
            logger.debug("‚úÖ FAISS —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
            return db
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å FAISS ({index_path}). –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º. –û—à–∏–±–∫–∞: {e}")


    logger.debug("–°–æ–∑–¥–∞—ë–º FAISS —Å –Ω—É–ª—è...")

    documents = load_train_csv("train_data_child.csv")
    if not documents:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")


    print("–î–æ–∫—É–º–µ–Ω—Ç—ã:", documents[:5])


    split_docs = split_documents(documents)
    texts = [d.page_content for d in split_docs]
    metadatas = [d.metadata for d in split_docs]


    print("texts:", texts[:5])

    logger.debug(f"–ß–∞–Ω–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {len(texts)}")


    db = FAISS.from_texts(
        texts=texts,
        embedding=embedding_wrapper,
        metadatas=metadatas  # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    )


    os.makedirs(index_path, exist_ok=True)
    db.save_local(index_path)
    logger.debug(f"FAISS —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {index_path}")

    return db


class GraphState(TypedDict):


    question: str     # –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    generation: str   # LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    autoanswer: str   # –î–≤–æ–∏—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –æ–± –æ—Ç–≤–µ—Ç–µ (–º–æ–∂–µ–º –ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –≤ –ø—Ä–∏—Ü–Ω–∏–ø–µ)
    max_retries: int  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    answers: int      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    #loop_step: Annotated[int, operator.add]
    loop_step: int
    documents: List[str]  # –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    relevant_tags: str
    choice: str
    age_group: str #–≤–æ–∑—Ä–∞—Å—Ç–Ω–∞—è –≥—Ä—É–ø–∞–ø

#–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è retrieve
def retriever_tag(db, allowed_tags=None, k=5):

    if allowed_tags:
        def custom_tag_filter(metadata):
            doc_tags = metadata.get('tags', [])
            # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å—ë –∫ —Å–ø–∏—Å–∫—É
            if not isinstance(doc_tags, (list, tuple)):
                doc_tags = [doc_tags] if isinstance(doc_tags, str) else []
            return any(tag in doc_tags for tag in allowed_tags)

        retriever = db.as_retriever(
            search_kwargs={
                "k": k,
                "filter": custom_tag_filter
            }
        )
    else:
        retriever = db.as_retriever(search_kwargs={"k": k})

    return retriever

def retrieve(state: GraphState):

    logger.debug("---–ü–û–ò–°–ö –° –£–ß–ï–¢–û–ú –ú–ï–¢–ê–î–ê–ù–ù–´–•---")
    # logger.debug(f"–í–°–ï –°–û–°–¢–û–Ø–ù–ò–ï –í RETRIEVE: {state}")
    logger.debug(f"–ö–ª—é—á–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {list(state.keys())}")

    relevant_tags = state.get("relevant_tags", []) #–ø–æ–ª—É—á–∞–µ–º —Ç—ç–≥–∏ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    logger.debug(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ç—ç–≥–∏: {relevant_tags}")

    question = state["question"]



    retriever_tags = retriever_tag(
         df,
         allowed_tags=relevant_tags,
         k=5 #–±–µ—Ä–µ–º k –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –æ–±—â–∏–º —Ç—ç–≥–∞–º –∏ —Å–µ–º–∞–Ω—Ç–∏–∫–µ
     )

    documents_tag = retriever_tags.invoke(question)
    logger.debug(f'documents_tag = {documents_tag}')


    return {"documents": documents_tag}

def reranke(state):
    logger.debug('---–†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï –î–û–ö–£–ú–ï–ù–¢–û–í (–ª–æ–∫–∞–ª—å–Ω–æ)---')

    documents = state.get('documents', [])
    if not documents:
        logger.debug("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç.")
        return {"autoanswer": "Yes"}

    text_docs = []
    for d in documents:
        if hasattr(d, "page_content"):
            text_docs.append(str(d.page_content))
        elif isinstance(d, dict) and "page_content" in d:
            text_docs.append(str(d["page_content"]))
        else:
            text_docs.append(str(d))

    question = state.get("question", "")
    logger.debug(f"–í–æ–ø—Ä–æ—Å: {question[:100]}")

    pairs = [(question, doc_text) for doc_text in text_docs]
    scores = cross_encoder.predict(pairs)

    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)
    reranked_documents = [documents[i] for i in ranked_indices]

    logger.debug("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞:")
    for rank, idx in enumerate(ranked_indices, start=1):
        score = scores[idx]
        snippet = text_docs[idx][:100]
        logger.debug(f"Rank {rank} | Score: {score:.4f} | Text snippet: {snippet}")

    return {"documents": reranked_documents}



def generate(state):

    logger.debug("---–°–ì–ï–ù–ï–†–ò–†–û–í–ê–¢–¨---")

    loop_step = state.get("loop_step", 0)

    # logger.debug('RAG generation')

    feedback = state.get("feedback", "")
    rag_prompt_formatted = rag_prompt.format(
        context=state["documents"],
        question=state["question"] + (
            "\n–¢–≤–æ–π –ø—Ä–æ—à–ª—ã–π –æ—Ç–≤–µ—Ç –º–Ω–µ –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è. –ò –≤–æ—Ç –ø–æ—á–µ–º—É: " + feedback if feedback else "") ,
        age_group = state['age_group']
    )
    generation = llm_generate(rag_prompt_formatted)
    logger.debug(f'generation={generation}')
    # logger.debug('----–§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ò–ù–û–°–¢–†–ê–ù–ù–´–• –°–ò–ú–í–û–õ–û–í----')
    filtered_generation=generation
    # filtered_generation = re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø0-9,.?\/—ë–Å%#*-‚Äî:‚Ññ\n]', ' ', generation)
    # filtered_generation = re.sub(r'\s+', ' ', filtered_generation).strip()
    return {"generation": filtered_generation, "loop_step": loop_step + 1}




def route_question(state):
    route_response = llm_json(prompt_text=state["question"], system_text=router_instructions)
    route_response = route_response.replace("```json", "").replace("```", "").strip()
    try:
        parsed = json.loads(route_response)
    except Exception as e:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç —Ä–æ—É—Ç–µ—Ä–∞: %s | raw: %s", e, route_response)

        return {"choice": "autoanswer", "relevant_tags": []}

    source = parsed.get("datasource")
    tags = parsed.get("tags", [])


    if tags:
        add_tags_to_session(tags)

    if source == "autoanswer":
        return {"choice": "autoanswer", "relevant_tags": []}
    elif source == "vectorstore":
        return {"choice": "vectorstore", "relevant_tags": tags}
    else:
        logger.warning("router returned unknown datasource: %s", source)
        return {"choice": "autoanswer", "relevant_tags": []}

#—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–≤—è–∑–∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä–∞ –∏ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
def router_to_retriever(state):
    choice = state.get("choice")
    print(f"–†–æ—É—Ç–µ—Ä –≤–∏–¥–∏—Ç choice: {choice}")

    if choice == "vectorstore":
        return "vectorstore"
    elif choice == "autoanswer":
        return "autoanswer"


def decide_to_generate(state):


    logger.debug("---–†–ï–õ–ï–í–ê–ù–¢–ù–´ –õ–ò –î–û–ö–£–ú–ï–ù–¢–´?---")
    question = state.get("question", "")
    autoanswer = state.get("autoanswer", "No")
    filtered_documents = state.get("documents", [])


    if autoanswer == "Yes":

        logger.debug(
            "---–ë–´–õ –í–´–ë–†–ê–ù –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –û–¢–í–ï–¢---"
        )
        return "autoanswer"
    else:

        logger.debug("---–†–ï–®–ï–ù–ò–ï: –ì–ï–ù–ï–†–ò–†–û–í–ê–¢–¨---")
        return "generate"


def judge_model(instructions: str, prompt_text: str):


    response = llm_client.chat.completions.create(
        model="mistralai/mistral-small-3.2-24b-instruct",
        messages=[
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": instructions  # —Ç–≤–æ–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
                    }
                ]
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt_text  # –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                    }
                ]
            }
        ],
        temperature=0.2
    )


    return response.choices[0].message.content

def grade_generation_v_documents_and_question(state):


    logger.debug("---–ü–†–û–í–ï–†–ò–¢–¨ –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ò---")
    question = state["question"]
    documents = state["documents"]
    generation = state["generation"]
    max_retries = state.get("max_retries", 3)

    max_retries = int(max_retries)
    loop_step = int(state.get("loop_step", 0))

    hallucination_prompt = hallucination_grader_prompt.format(
        documents=documents, generation=generation
    )
    result_text = judge_model(
        instructions=hallucination_grader_instructions,
        prompt_text=hallucination_prompt
    )


    result_text = result_text.replace("```json", "").replace("```", "").strip()

    try:
        if not result_text:
            raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç —Å—É–¥—å–∏")
        result_json = json.loads(result_text)
        grade = result_json.get("binary_score", "no")
        explanation = result_json.get("explanation", "")
    except Exception as e:
        grade = "no"
        explanation = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ —Å—É–¥—å–∏: {result_text}. Exception: {e}"
        logger.warning(explanation)

    logger.debug(f"---–û–¶–ï–ù–ö–ê –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ò: {grade} --- –û–ë–™–Ø–°–ù–ï–ù–ò–ï: {explanation}")

    if grade.lower() == "yes":
        logger.debug("---–†–ï–®–ï–ù–ò–ï: –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–°–ù–û–í–ê–ù–ê –ù–ê –î–û–ö–£–ú–ï–ù–¢–ê–•---")
        logger.debug("---–û—Ü–µ–Ω–∫–∞: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ø—Ä–æ—Ç–∏–≤ –í–û–ü–†–û–°–ê---")

        answer_grader_prompt_formatted = answer_grader_prompt.format(
            question=question, generation=generation
        )
        result_text = llm_json(answer_grader_prompt_formatted, answer_grader_instructions)
        result_text = result_text.replace("```json", "").replace("```", "").strip()
        # lean_text = result_text.replace("```json", "").replace("```", "").strip()


        json_start = result_text.find("{")
        if json_start != -1:
            json_text = result_text[json_start:]
            try:
                if not result_text:
                    raise ValueError("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–∞")
                result_json = json.loads(json_text)
                grade_answer = result_json.get("binary_score", "no")
            except Exception as e:
                grade_answer = "no"
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –æ—Ç–≤–µ—Ç–∞: {result_text}. Exception: {e}")

        if grade_answer.lower() == "yes":
            logger.debug("---–†–ï–®–ï–ù–ò–ï: GENERATION –û–ë–†–ê–©–ê–ï–¢–°–Ø –ö –í–û–ü–†–û–°–£---")
            return "useful"
        elif loop_step <= max_retries:
            logger.debug("---–†–ï–®–ï–ù–ò–ï: GENERATION –ù–ï –û–¢–í–ï–ß–ê–ï–¢ –ù–ê –í–û–ü–†–û–°---")
            return "not useful"
        else:
            logger.debug("---–†–ï–®–ï–ù–ò–ï: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û –ü–û–í–¢–û–†–ù–´–• –ü–û–ü–´–¢–û–ö –î–û–°–¢–ò–ì–ù–£–¢–û---")
            return "max retries"

    elif loop_step <= max_retries:
        logger.debug("---–†–ï–®–ï–ù–ò–ï: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ù–ï –û–°–ù–û–í–ê–ù–ê –ù–ê –î–û–ö–£–ú–ï–ù–¢–ê–•, –ü–û–í–¢–û–†–ò–¢–ï –ü–û–ü–´–¢–ö–£---")
        return "not supported"
    else:
        logger.debug("---–†–ï–®–ï–ù–ò–ï: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û –ü–û–í–¢–û–†–ù–´–• –ü–û–ü–´–¢–û–ö –î–û–°–¢–ò–ì–ù–£–¢–û---")
        return "max retries"



workflow = StateGraph(GraphState)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤
workflow.add_node("autoanswer", autoanswer)  # web search
workflow.add_node("retrieve", retrieve)  # retrieve
workflow.add_node("reranker", reranke)# reranke
# workflow.add_node("grade_documents", grade_documents)  # grade documents
workflow.add_node("generate", generate)  # generate
workflow.add_node("route", route_question)

workflow.set_entry_point("route")

#–¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Å–≤—è–∑–∏ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ –∏ —Ä–æ—É—Ç–µ—Ä–∞
workflow.add_conditional_edges(
    "route",
    router_to_retriever,
    {
        "vectorstore": "retrieve",
        "autoanswer": "autoanswer"
    }
)
workflow.add_edge("autoanswer", END)
# workflow.add_edge("retrieve", "grade_documents")
# workflow.add_edge("grade_documents", "reranker")
workflow.add_edge("retrieve", "reranker")
workflow.add_conditional_edges(
    "reranker",
    decide_to_generate,
    {
        "autoanswer": "autoanswer",
        "generate": "generate",
    },
)
workflow.add_conditional_edges(
    "generate",
    grade_generation_v_documents_and_question,
    {
        "not supported": "generate",
        "useful": END,
        "not useful": "autoanswer",
        "max retries": END,
    },
)


graph = workflow.compile()

global df
df = indexed_df()
retriever = df.as_retriever(k=4)


def answer_question(question: str, age_group: str = None, max_retries: int = 3) -> str:

    logger.debug(f"–ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å: {question}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å FAISS
    df = indexed_df()
    logger.debug("FAISS –∏–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω")
    retriever = df.as_retriever(k=4)
    logger.debug("Retriever —Å–æ–∑–¥–∞–Ω")


    inputs = {
        "question": question,
        "max_retries": max_retries,
        "age_group": age_group
    }

    final_answer = "–û—à–∏–±–∫–∞: –æ—Ç–≤–µ—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω"

    # –ü—Ä–æ–≥–æ–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
    for event in graph.stream(inputs, stream_mode="values"):
        if "generation" in event and hasattr(event["generation"], "content"):
            final_answer = event["generation"].content
            break

    logger.debug(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {final_answer}")
    return final_answer


#if __name__ == "__main__":
#    test_question = "–ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ —à–∞–Ω—Ç–∞–∂–∏—Ä—É—é—Ç –∏–Ω—Ç–∏–º–Ω—ã–º–∏ —Ñ–æ—Ç–æ –∏ –≤–∏–¥–µ–æ?"
#    df = indexed_df()
#    logger.debug('Create retriever')

#    retriever = df.as_retriever(k=4)
#    inputs = {"question": test_question, "max_retries": 2}
#    print(f"\nüîπ –í–æ–ø—Ä–æ—Å: {test_question}\n")


#    for event in graph.stream(inputs, stream_mode="values"):
#        pass  # –ø—Ä–æ—Å—Ç–æ –¥–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞

#
#    final_answer = event.get("generation", "–û—à–∏–±–∫–∞: –æ—Ç–≤–µ—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

#    print("\n–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
#    print(final_answer)


#import anyio



# async def process_question(question_text, graph):
#
#     inputs = {"question": question_text, "max_retries": 2}
#
#     for attempt in range(1, 3 + 1):
#         try:
#             # logger.debug(f" –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {question_text}")
#             final_answer = None
#
#             async for event in graph.astream(inputs, stream_mode="values"):
#                 final_answer = event.get("generation")
#
#             if final_answer and final_answer.strip():
#                 # logger.debug(f" –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å: {question_text}")
#                 return final_answer
#
#             raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
#
#         except Exception as e:
#             # logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{question_text}' (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}")
#             if attempt < 3:
#                 # logger.debug(f" –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...")
#                 await anyio.sleep(10)
#             else:
#                 # logger.error(f" –í—Å–µ {3} –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {question_text}")
#                 return "–ö–∞–∂–µ—Ç—Å—è,—è –µ—â–µ –Ω–µ –Ω–∞—É—á–∏–ª—Å—è –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ø–æ–¥–æ–±–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã!:("
#
#
# async def main():
#     csv_path = "./questions.csv"
#     output_path = "submission.csv"
#
#     # logger.debug(" –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤...")
#
#
#     questions = pd.read_csv(csv_path)
#     questions_list = questions['–í–æ–ø—Ä–æ—Å'].tolist()
#
#
#     global df
#     df = indexed_df()
#
#     #global retriever
#     #retriever = df.as_retriever(search_kwargs={"k":3})
#
#     # logger.debug(f"–í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(questions_list)}")
#
#     results = []
#
#
#     async with anyio.create_task_group() as tg:
#         async def handle_question(q):
#             answer = await process_question(q, graph)
#             results.append((q, answer))
#
#         for q in questions_list:
#             tg.start_soon(handle_question, q)
#
#
#     question_to_answer = dict(results)
#     questions["–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å"] = questions["–í–æ–ø—Ä–æ—Å"].map(question_to_answer)
#
#
#     # questions["–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å"] = questions["–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å"].apply(clean_generation)
#
#     # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
#     questions.to_csv(output_path, index=False)
#     # logger.debug(f" –û—Ç–≤–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª {output_path}")
#     print(f" –û—Ç–≤–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
#
#
# if __name__ == "__main__":
#    anyio.run(main)